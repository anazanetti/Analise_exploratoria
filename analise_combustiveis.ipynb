{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl #biblioteca para ler o arquivo .xlsx\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "#from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = 'notebook'  # Configura o renderizador para notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio        = 'datasets'\n",
    "arquivo_extensao = '.csv'\n",
    "lista_arquivos   = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "##### Conjunto de Dados\n",
    "\n",
    "Série Histórica de Preços de Combustíveis e de GLP   \n",
    "https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis\n",
    "\n",
    "A análise será realizada no **Conjunto de Dados semanais agrupados por semestre (2013 a 2023)**, considerando somente os **Combustíveis automotivos**, totalizando 21 arquivos csv.\n",
    "<br><br>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise da Estrutura dos Dados (antes da limpeza)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados          = pd.DataFrame()    \n",
    "df_estrutra_dados = pd.DataFrame()\n",
    "\n",
    "# Lista os arquivos do diretório\n",
    "for arquivo in os.listdir(diretorio):\n",
    "    if arquivo.endswith(arquivo_extensao):\n",
    "       lista_arquivos.append(arquivo)\n",
    "\n",
    "# Carrega o DataFrame \n",
    "for dataset in lista_arquivos:\n",
    "    caminho_arquivo   = os.path.join(diretorio, dataset)\n",
    "    df_dados          = pd.read_csv(caminho_arquivo, sep=';', low_memory=False)\n",
    "    df_estrutra_dados = pd.concat([df_estrutra_dados, df_dados], ignore_index=True)\n",
    "\n",
    "print(\"Dimensões da base\")\n",
    "print(\"-----------------\")\n",
    "print(\"\")\n",
    "print(f\"Linhas: {len(df_estrutra_dados)}\")\n",
    "print(f\"Colunas: {len(df_estrutra_dados.iloc[0])}\")\n",
    "    \n",
    "print(\"\")\n",
    "print(\"\") \n",
    "print(\"Estrutura\")\n",
    "print(\"---------\")\n",
    "print(\"\")\n",
    "print(df_estrutra_dados.info())\n",
    "\n",
    "print(\"\")\n",
    "print(\"\") \n",
    "print(\"Qtde de campos nulos\")\n",
    "print(\"--------------------\")\n",
    "print(\"\")\n",
    "print(df_estrutra_dados.isnull().sum())\n",
    "\n",
    "# Visualização do DataFrame (Head e Tail)\n",
    "print(display(df_estrutra_dados)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise da Estrutura dos Dados (após a limpeza)\n",
    "\n",
    "Otimização:\n",
    "* Colunas não consideradas na análise serão excluídas do dataframe\n",
    "* A fim de um melhor aproveitamento de espaço, algumas colunas terão o seu tipo alterado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados        = pd.DataFrame()\n",
    "df_dados_limpos = pd.DataFrame()\n",
    "\n",
    "for dataset in lista_arquivos:\n",
    "    caminho_arquivo = os.path.join(diretorio, dataset)\n",
    "    df_dados        = pd.read_csv(caminho_arquivo,\n",
    "                                  sep=';', thousands = '.', decimal = ',', \n",
    "                                  dtype = {'Regiao - Sigla': 'category',\n",
    "                                           'Estado - Sigla': 'category',\n",
    "                                           'Valor de Compra': np.float64})\n",
    "    \n",
    "    df_dados_limpos = pd.concat([df_dados_limpos, df_dados], ignore_index=True)\n",
    "    \n",
    "df_dados_limpos.drop(columns=['Nome da Rua',\n",
    "                              'Numero Rua',\n",
    "                              'Complemento',\n",
    "                              'Bairro',\n",
    "                              'Cep',\n",
    "                              'Valor de Compra'], inplace=True)    \n",
    "df_dados_limpos.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
